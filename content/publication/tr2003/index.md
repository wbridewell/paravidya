---
title: 'Extracting Plausible Explanations of Anomalous Data'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
  - admin
  - Bruce G. Buchanan

# Author notes (optional)
# author_notes:
#   - 'Equal contribution'
#   - 'Equal contribution'

date: '2003-01-10'
doi: ''

# Schedule page publish date (NOT publication's date).
publishDate: '2017-01-01T00:00:00Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ['4']

# Publication name and optional abbreviated publication name.
publication: Technical Report CS-TR-03-105. Computer Science Department, University of Pittsburgh
publication_short: Tech. Report, U of Pittsburgh

abstract: "We present a perspective on theory revision that characterizes the resulting revisions as explanations of anomalous data (i.e., data that contradict a given model). Additionally, we emphasize the plausibility of these explanations as opposed to the performance of a revised model. An explanation generator implementing (part of) John Stuart Mill's Method of Induction was constructed that divides the available data into meaningful subsets to better resolve the anomalies. A domain expert judged the plausibility of the resulting explanations. We found that using relevant subsets of data can provide plausible explanations not generated when using all the data and that identifying plausible explanations can help select among equally possible revisions."

# Summary. An optional shortened abstract.
summary: "An explanation generator implementing (part of) John Stuart Mill's Method of Induction was constructed that divides the available data into meaningful subsets to better resolve the anomalies. We found that using relevant subsets of data can provide plausible explanations not generated when using all the data and that identifying plausible explanations can help select among equally possible revisions."


tags: [machine learning, biomedical informatics]

# Display this page in the Featured widget?
featured: false

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# image:
#   caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
#   focal_point: ''
#   preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
  - biomedical-informatics

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ''
---